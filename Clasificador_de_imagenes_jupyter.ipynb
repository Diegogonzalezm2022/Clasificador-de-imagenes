{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "14RggZ8SI-Lb__1z3E019UBqDFA-U9Jy6",
      "authorship_tag": "ABX9TyNWkuWfTNIQ37zZnQQ4kEp4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.io import decode_image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "7hb_cQ2FRJSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset\n",
        "class SkinDiseaseDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.labels_map={}\n",
        "        labels_list=[]\n",
        "        num=0\n",
        "        for dir in os.listdir(self.img_dir):\n",
        "            category=dir\n",
        "            self.labels_map[num]=category\n",
        "            for file in os.listdir(os.path.join(img_dir, dir)):\n",
        "                labels_list.append((file, num))\n",
        "            num+=1\n",
        "        self.img_labels=pandas.DataFrame.from_records(labels_list)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.labels_map[self.img_labels.iloc[idx, 1]], self.img_labels.iloc[idx, 0])\n",
        "        image = decode_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "eKPBn7BHPSxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing utilities\n",
        "def train(model, dataset, EPOCHS, batch_size, optimizer, criterion, device, transform):\n",
        "    train_dataset=SkinDiseaseDataset(os.path.join(dataset, \"train\"), transform=transform)\n",
        "    train_loader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataset=SkinDiseaseDataset(os.path.join(dataset, \"validation\"), transform=transform)\n",
        "    val_loader=DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'dev_loss': [],\n",
        "        'dev_acc': [],\n",
        "    }\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()  # Limpiar gradientes\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)  # Forward\n",
        "            n_classes = outputs.shape[1]\n",
        "            labels_one_hot = F.one_hot(labels, num_classes=n_classes).float()\n",
        "\n",
        "            loss = criterion(outputs, labels_one_hot)  # Pérdida\n",
        "            loss.backward()  # Backward\n",
        "            optimizer.step()  # Update\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Accuracy en train\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        avg_train_loss = running_loss / max(1, len(train_loader))\n",
        "        train_acc = 100.0 * correct / max(1, total)\n",
        "\n",
        "        # ---- Validación (loss) ----\n",
        "        model.eval()\n",
        "        dev_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                n_classes = outputs.shape[1]\n",
        "                labels_one_hot = F.one_hot(labels, num_classes=n_classes).float()\n",
        "                dev_loss = criterion(outputs, labels_one_hot)\n",
        "                dev_running_loss += dev_loss.item()\n",
        "        avg_dev_loss = dev_running_loss / max(1, len(val_loader))\n",
        "\n",
        "        # ---- Validación (accuracy) usando tu función evaluate ----\n",
        "        dev_acc = evaluate(model, device, data=dataset, BATCH_SIZE=batch_size)[0]  # imprime y devuelve accuracy\n",
        "\n",
        "        # Guardar histórico\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['dev_loss'].append(avg_dev_loss)\n",
        "        history['dev_acc'].append(dev_acc)\n",
        "\n",
        "        # Log por época (conciso y claro)\n",
        "        print(f'[Epoch {epoch + 1}] '\n",
        "              f'train_loss: {avg_train_loss:.3f} | train_acc: {train_acc:.2f}% | '\n",
        "              f'dev_loss: {avg_dev_loss:.3f} | dev_acc: {dev_acc:.2f}%')\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def evaluate(model, device, data, BATCH_SIZE):\n",
        "    transform=transforms.Compose([transforms.ToPILImage(), transforms.Resize((82, 87)), transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    test_dataset=SkinDiseaseDataset(os.path.join(data, \"test\"), transform=transform)\n",
        "    test_loader=DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    model.eval()  # Poner el modelo en modo evaluación\n",
        "    correct = 0\n",
        "    total = test_loader.dataset.__len__()  # Total de muestras en el conjunto de test\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():  # No calcular gradientes\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Mover datos al dispositivo\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            _, predicted = torch.max(outputs, 1)  # Obtener las predicciones\n",
        "            correct += (predicted == labels).sum().item()  # Actualizar el contador de aciertos\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    accuracy = 100 * correct / total if total > 0 else 0.0\n",
        "    return accuracy, cm\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Dibuja las curvas de loss y accuracy (train y dev) guardadas en el diccionario 'history'.\n",
        "    Espera claves: 'train_loss', 'train_acc', 'dev_loss', 'dev_acc'.\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    # --- Loss ---\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
        "    plt.plot(epochs, history['dev_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # --- Accuracy ---\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history['train_acc'], label='Train Accuracy')\n",
        "    plt.plot(epochs, history['dev_acc'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def print_cm(cm, classes):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def runNN(model, DEVICE, data, epochs, BATCH_SIZE, optimizer, loss, transform):\n",
        "    classes=[]\n",
        "    for dir in os.listdir(os.path.join(data, \"test\")): classes.append(dir)\n",
        "    model, history=train(model, data, epochs, BATCH_SIZE, optimizer, loss, DEVICE, transform)\n",
        "    accuracy, cm=evaluate(model, DEVICE, data, BATCH_SIZE)\n",
        "    print(f\"eval_acc: {accuracy:.2f}%\")\n",
        "    print(model)\n",
        "    plot_training_history(history)\n",
        "    print_cm(cm, classes)"
      ],
      "metadata": {
        "id": "P70sFWLBQ6NF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}